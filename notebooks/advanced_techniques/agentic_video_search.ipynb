{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3743e5aa-5a08-4b37-a545-4e7461e14468",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mongodb-developer/GenAI-Showcase/blob/main/notebooks/advanced_techniques/agentic_video_search.ipynb)\n",
        "\n",
        "[![View Article](https://img.shields.io/badge/View%20Article-blue)](https://www.mongodb.com/company/blog/technical/agentic-video-search/?utm_campaign=devrel&utm_source=cross-post&utm_medium=organic_social&utm_content=https%3A%2F%2Fgithub.com%2Fmongodb-developer%2FGenAI-Showcase&utm_term=apoorva.joshi)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "becc445d-5a51-4a8a-abeb-ceab0b54c167",
      "metadata": {},
      "source": [
        "# Building an Agentic Video Search System using Voyage AI and MongoDB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8beabeb0-f231-4e56-9af3-3178be3c92cf",
      "metadata": {},
      "source": [
        "## Step 1: Install required packages\n",
        "\n",
        "- **voyageai**: Voyage AI's Python SDK\n",
        "- **pymongo**: MongoDB's Python driver\n",
        "- **anthropic**: Anthropic's Python SDK\n",
        "- **huggingface_hub**: Python library for interacting with the Hugging Face Hub\n",
        "- **ffmpeg-python**: Python wrapper for `ffmpeg`\n",
        "- **tqdm**: Python library to display progress bars for loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e9d5d1c4-614b-42de-9e15-c02146e8be89",
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -qU voyageai==0.3.7 pymongo==4.15.5 anthropic==0.75.0 huggingface-hub==1.2.3 ffmpeg-python==0.2.0 tqdm==4.67.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4803c8c-eb59-44aa-9306-5e49088add6b",
      "metadata": {},
      "source": [
        "You'll also need to install the `ffmpeg` binary itself. To do this, run the following commands from the terminal and note the path to the `ffmpeg` installation:\n",
        "\n",
        "#### MacOS\n",
        "\n",
        "```\n",
        "brew install ffmpeg\n",
        "```\n",
        "\n",
        "#### Linux\n",
        "\n",
        "```\n",
        "sudo apt-get install ffmpeg\n",
        "```\n",
        "\n",
        "#### Windows\n",
        "* Download the executable from [ffmpeg.org](https://ffmpeg.org/download.html#build-windows)\n",
        "* Extract the downloaded zip file\n",
        "* Note the path to the `bin` folder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aafea857-7c11-48ff-a5cc-21a44de2f02b",
      "metadata": {},
      "source": [
        "## Step 2: Setup prerequisites\n",
        "\n",
        "**Voyage AI**\n",
        "- [Obtain a Voyage AI API key](https://dashboard.voyageai.com/organization/api-keys)\n",
        "\n",
        "**MongoDB**\n",
        "- Register for a [free MongoDB Atlas account](https://www.mongodb.com/cloud/atlas/register)\n",
        "- [Create a new database cluster](https://www.mongodb.com/docs/guides/atlas/cluster/)\n",
        "- [Obtain the connection string](https://www.mongodb.com/docs/guides/atlas/connection-string/) for your database cluster\n",
        "\n",
        "**Anthropic**\n",
        "- [Obtain an Anthropic API key](https://platform.claude.com/settings/keys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "12b1c0b3-b18a-4fda-b730-0693b5259a8f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "import anthropic\n",
        "import voyageai\n",
        "from pymongo import MongoClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "d05bb72f-bebc-4255-8206-7a3b70b3d302",
      "metadata": {},
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter your Voyage API key: ········\n"
          ]
        }
      ],
      "source": [
        "# Set Voyage API key as an environment variable\n",
        "os.environ[\"VOYAGE_API_KEY\"] = getpass.getpass(\"Enter your Voyage API key:\")\n",
        "# Initialize the Voyage AI client\n",
        "voyage_client = voyageai.Client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "662fc622-7d64-4d12-acb4-8eaa425aa829",
      "metadata": {},
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter your MongoDB connection string: ········\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'ok': 1.0,\n",
              " '$clusterTime': {'clusterTime': Timestamp(1767387291, 1),\n",
              "  'signature': {'hash': b'\\xf8\\xbcI\\xcf\\x81DR\\xc1\\xcdO\\xcf\\xa8\\x1d\\xc9\\x1do\\x14dH\\xf2',\n",
              "   'keyId': 7558184680432861186}},\n",
              " 'operationTime': Timestamp(1767387291, 1)}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the MongoDB connection string\n",
        "MONGODB_URI = getpass.getpass(\"Enter your MongoDB connection string:\")\n",
        "# Initialize the MongoDB client\n",
        "mongodb_client = MongoClient(\n",
        "    MONGODB_URI, appname=\"devrel.showcase.agentic_video_search\"\n",
        ")\n",
        "# Check MongoDB connection\n",
        "mongodb_client.admin.command(\"ping\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f0baa8a5-8625-4d41-a2ab-13404b13f3cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Enter your Anthropic API key: ········\n"
          ]
        }
      ],
      "source": [
        "# Set Anthropic API key as an environment variable\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass(\"Enter your Anthropic API key:\")\n",
        "# Initialize the Anthropic client\n",
        "anthropic_client = anthropic.Anthropic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "b252c917-c714-4e6b-bd55-a420161bb96f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make ffmpeg accessible from the notebook\n",
        "# Replace /path/to/ffmpeg with your ffmpeg path\n",
        "os.environ[\"PATH\"] = f\"/path/to/ffmpeg:{os.environ['PATH']}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c58c9820-c53b-49e5-8023-b5234cf7d817",
      "metadata": {},
      "source": [
        "## Step 3: Download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "6b1cef44-0d97-44fb-878e-7e3872c0d8fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "d698eba9-fa77-4714-b7d5-558aecd9e93d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5153fe076e7c460eb032a40783accb03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71591b99eceb486b808022f317715839",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_dir = snapshot_download(\n",
        "    repo_id=\"MongoDB/cooking-videos-with-captions\",\n",
        "    repo_type=\"dataset\",\n",
        "    local_dir=\"./videos/\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c33737d-30bb-4d41-add8-01e4fcd32b61",
      "metadata": {},
      "source": [
        "## Step 4: Segment the videos using captions\n",
        "\n",
        "`voyage-multimodal-3.5` has a 32k token limit or a 20 MB file size limit for video inputs. When working with large videos, split them into smaller segments prior to embedding to keep them within the model’s limits. Splitting videos at natural breaks in captions/transcripts ensures that related frames remain together, resulting in more focused embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "47ed4b96-5e5a-4460-83fa-d4b0eedc1d39",
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "import json\n",
        "\n",
        "import ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "d38e4b76-9dd9-4b3a-92fa-f2c1bba36fe5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory to store video segments\n",
        "segments_dir = \"./videos/segments\"\n",
        "os.makedirs(segments_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "29a4deaa-1364-4294-9cb5-37f661d97157",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_videos = len(glob.glob(os.path.join(data_dir, \"video_*.mp4\")))\n",
        "num_videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "7596f970-84ea-466a-b054-caf159d788e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "docs = []\n",
        "for num in range(num_videos):\n",
        "    video_id = f\"video_{num:03d}\"\n",
        "    video_path = os.path.join(data_dir, f\"{video_id}.mp4\")\n",
        "    captions_path = os.path.join(data_dir, f\"{video_id}.json\")\n",
        "\n",
        "    # Load captions\n",
        "    with open(captions_path) as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    captions = data[\"captions\"]\n",
        "    title = data[\"title\"]\n",
        "\n",
        "    # Segment the video based on captions\n",
        "    for i, caption in enumerate(captions):\n",
        "        segment_id = f\"segment_{i:03d}\"\n",
        "        # Create segment\n",
        "        output_file = os.path.join(segments_dir, f\"{video_id}_{segment_id}.mp4\")\n",
        "        (\n",
        "            ffmpeg.input(video_path, ss=caption[\"start\"], to=caption[\"end\"])\n",
        "            .output(output_file, c=\"copy\")\n",
        "            .overwrite_output()\n",
        "            .run(quiet=True)\n",
        "        )\n",
        "        # Create segment document to write to MongoDB\n",
        "        doc = {\n",
        "            \"segment_id\": segment_id,\n",
        "            \"video_id\": video_id,\n",
        "            \"caption\": caption[\"text\"],\n",
        "            \"metadata\": {\n",
        "                \"video_title\": title,\n",
        "                \"start\": caption[\"start\"],\n",
        "                \"end\": caption[\"end\"],\n",
        "            },\n",
        "        }\n",
        "        docs.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "2c8632a0-4fa6-4ad5-a031-511c37db0ccc",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'segment_id': 'segment_000',\n",
              " 'video_id': 'video_000',\n",
              " 'caption': 'Chef Marguerite Dubois, wearing her signature striped apron, rolls out the laminated croissant dough using a wooden rolling pin on a granite countertop dusted with flour.',\n",
              " 'metadata': {'video_title': 'Classic French Croissants with Chef Marguerite Dubois',\n",
              "  'start': 0,\n",
              "  'end': 7}}"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Preview a segment doc\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f5878f1-0929-4c6b-8d7c-f66a306f34cf",
      "metadata": {},
      "source": [
        "## Step 5: Embed the video segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "f62de0e8-d263-4fb2-8f22-e5882b9aee9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from voyageai.video_utils import Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "cf6bde8c-3d20-47cb-952d-850a50cd9d6e",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODEL_NAME = \"voyage-multimodal-3.5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "id": "5874fbd5-5340-4d26-ae1d-44e20b4ff8f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_embeddings(inputs: list[list], input_type: str) -> list[list]:\n",
        "    \"\"\"\n",
        "    Generate embeddings using Voyage AI's latest multimodal embedding model.\n",
        "\n",
        "    Args:\n",
        "        inputs (list[list]): Inputs as a list of lists\n",
        "        input_type (str): Type of input. Can be one of \"document\" or \"query\"\n",
        "\n",
        "    Returns:\n",
        "        list[list]: List of embeddings\n",
        "    \"\"\"\n",
        "    embeddings = voyage_client.multimodal_embed(\n",
        "        inputs=inputs, model=MODEL_NAME, input_type=input_type\n",
        "    ).embeddings\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "af2e7192-1bf1-4f84-8726-fc296ba3c7b7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/17 [00:00<?, ?it/s]\u001b[A\n",
            "  6%|▌         | 1/17 [00:07<02:05,  7.86s/it]\u001b[A\n",
            " 12%|█▏        | 2/17 [00:15<01:59,  8.00s/it]\u001b[A\n",
            " 18%|█▊        | 3/17 [00:23<01:47,  7.68s/it]\u001b[A\n",
            " 24%|██▎       | 4/17 [00:31<01:40,  7.73s/it]\u001b[A\n",
            " 29%|██▉       | 5/17 [00:37<01:27,  7.26s/it]\u001b[A\n",
            " 35%|███▌      | 6/17 [00:44<01:20,  7.28s/it]\u001b[A\n",
            " 41%|████      | 7/17 [00:52<01:13,  7.39s/it]\u001b[A\n",
            " 47%|████▋     | 8/17 [01:02<01:14,  8.24s/it]\u001b[A\n",
            " 53%|█████▎    | 9/17 [01:06<00:55,  6.95s/it]\u001b[A\n",
            " 59%|█████▉    | 10/17 [01:13<00:49,  7.00s/it]\u001b[A\n",
            " 65%|██████▍   | 11/17 [01:22<00:44,  7.47s/it]\u001b[A\n",
            " 71%|███████   | 12/17 [01:29<00:37,  7.44s/it]\u001b[A\n",
            " 76%|███████▋  | 13/17 [01:36<00:29,  7.39s/it]\u001b[A\n",
            " 82%|████████▏ | 14/17 [01:42<00:20,  6.92s/it]\u001b[A\n",
            " 88%|████████▊ | 15/17 [01:48<00:13,  6.60s/it]\u001b[A\n",
            " 94%|█████████▍| 16/17 [01:55<00:06,  6.72s/it]\u001b[A\n",
            "100%|██████████| 17/17 [02:02<00:00,  7.18s/it]\u001b[A\n"
          ]
        }
      ],
      "source": [
        "for doc in tqdm(docs):\n",
        "    video_obj = Video.from_path(\n",
        "        path=f\"{segments_dir}/{doc['video_id']}_{doc['segment_id']}.mp4\",\n",
        "        model=MODEL_NAME,\n",
        "    )\n",
        "    # Embed the video segment and its caption together\n",
        "    embeddings = generate_embeddings([[video_obj, doc[\"caption\"]]], \"document\")\n",
        "    # Add the embedding to the MongoDB document\n",
        "    doc[\"embedding\"] = embeddings[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "9842073e-eafa-4fa9-a552-26c16bc14871",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['segment_id', 'video_id', 'caption', 'metadata', 'embedding'])"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ensure that embeddings were added to the MongoDB docs\n",
        "docs[0].keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd2c7732-c279-43d4-8c44-2726d47342cc",
      "metadata": {},
      "source": [
        "## Step 6: Ingest documents into MongoDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "0db8f30e-966e-45c9-8bdf-b5269ab5d2ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "db = mongodb_client[\"video_search\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "363db084-bc68-4321-b608-2945545444a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "collection = db[\"segments\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "ee430180-9f28-4bf9-bf6c-3ffadba3389c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeleteResult({'n': 0, 'electionId': ObjectId('7fffffff0000000000000048'), 'opTime': {'ts': Timestamp(1767391621, 1), 't': 72}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1767391621, 1), 'signature': {'hash': b'\\x01)\\xa3v^\\x13N\\xb8\\xc7Ny\\x97\\xf0\\xa5\\x885\\x92?M\\xcd', 'keyId': 7558184680432861186}}, 'operationTime': Timestamp(1767391621, 1)}, acknowledged=True)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Delete existing documents from collection\n",
        "collection.delete_many({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "8676d51c-e492-42a5-92b1-c5a804ae845e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "InsertManyResult([ObjectId('695841876d5b2abc43875acc'), ObjectId('695841876d5b2abc43875acd'), ObjectId('695841876d5b2abc43875ace'), ObjectId('695841876d5b2abc43875acf'), ObjectId('695841876d5b2abc43875ad0'), ObjectId('695841876d5b2abc43875ad1'), ObjectId('695841876d5b2abc43875ad2'), ObjectId('695841876d5b2abc43875ad3'), ObjectId('695841876d5b2abc43875ad4'), ObjectId('695841876d5b2abc43875ad5'), ObjectId('695841876d5b2abc43875ad6'), ObjectId('695841876d5b2abc43875ad7'), ObjectId('695841876d5b2abc43875ad8'), ObjectId('695841876d5b2abc43875ad9'), ObjectId('695841876d5b2abc43875ada'), ObjectId('695841876d5b2abc43875adb'), ObjectId('695841876d5b2abc43875adc')], acknowledged=True)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Insert `docs` into the collection\n",
        "collection.insert_many(docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "222dc148-c00c-4218-be81-41c008ac5f2f",
      "metadata": {},
      "source": [
        "## Step 7: Create search indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "d9645c8a-7067-45ab-98a9-004c3c089e20",
      "metadata": {},
      "outputs": [],
      "source": [
        "from pymongo.operations import SearchIndexModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "d45e5bb8-2ccb-4264-8df6-37f1ba8690ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full-text search index definition\n",
        "fts_model = SearchIndexModel(\n",
        "    name=\"fts-index\",\n",
        "    definition={\n",
        "        \"mappings\": {\"dynamic\": False, \"fields\": {\"caption\": {\"type\": \"string\"}}}\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "9fdd1f6e-7c52-4995-ac79-596d4726d462",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vector search index definition\n",
        "vs_model = SearchIndexModel(\n",
        "    name=\"vector-index\",\n",
        "    type=\"vectorSearch\",\n",
        "    definition={\n",
        "        \"fields\": [\n",
        "            {\n",
        "                \"type\": \"vector\",\n",
        "                \"path\": \"embedding\",\n",
        "                \"numDimensions\": 1024,\n",
        "                \"similarity\": \"cosine\",\n",
        "            }\n",
        "        ]\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "e8517ad0-84a7-463a-9c46-069bf8cfb286",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['fts-index', 'vector-index']"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collection.create_search_indexes([fts_model, vs_model])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d82cae7-5fe8-4278-bbe4-b8a329a1802d",
      "metadata": {},
      "source": [
        "## Step 8: Define search functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "f7af9203-cc46-4361-bedd-bed3cc1d87d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "def format_time(seconds: int) -> str:\n",
        "    \"\"\"\n",
        "    Format a second timestamp as min:sec.\n",
        "\n",
        "    Args:\n",
        "        seconds (int): Time in seconds\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted timestamp\n",
        "    \"\"\"\n",
        "    mins = int(seconds // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    return f\"{mins}:{secs:02d}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "id": "360aa134-ca0f-4a21-84ba-0aa4edc12692",
      "metadata": {},
      "outputs": [],
      "source": [
        "def vector_search(query: str) -> None:\n",
        "    \"\"\"\n",
        "    Retrieve relevant video segments using vector search.\n",
        "\n",
        "    Args:\n",
        "        query (str): User query string\n",
        "    \"\"\"\n",
        "    query_embedding = generate_embeddings([[query]], \"query\")[0]\n",
        "    pipeline = [\n",
        "        {\n",
        "            \"$vectorSearch\": {\n",
        "                \"index\": \"vector-index\",\n",
        "                \"queryVector\": query_embedding,\n",
        "                \"path\": \"embedding\",\n",
        "                \"numCandidates\": 200,\n",
        "                \"limit\": 3,\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"$project\": {\n",
        "                \"_id\": 0,\n",
        "                \"video_title\": \"$metadata.video_title\",\n",
        "                \"start\": \"$metadata.start\",\n",
        "                \"end\": \"$metadata.end\",\n",
        "                \"score\": {\"$meta\": \"vectorSearchScore\"},\n",
        "            }\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    results = collection.aggregate(pipeline)\n",
        "    for result in results:\n",
        "        print(\n",
        "            f\"{result.get('video_title')} ({format_time(result.get('start'))} - {format_time(result.get('end'))})\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "id": "765fb1f3-a410-4ea6-89b4-689b57c83e15",
      "metadata": {},
      "outputs": [],
      "source": [
        "def hybrid_search(query: str) -> None:\n",
        "    \"\"\"\n",
        "    Retrieve relevant video segments using hybrid search.\n",
        "\n",
        "    Args:\n",
        "        query (str): User query string\n",
        "    \"\"\"\n",
        "    query_embedding = generate_embeddings([[query]], \"query\")[0]\n",
        "    pipeline = [\n",
        "        {\n",
        "            \"$rankFusion\": {\n",
        "                \"input\": {\n",
        "                    \"pipelines\": {\n",
        "                        \"vector_pipeline\": [\n",
        "                            {\n",
        "                                \"$vectorSearch\": {\n",
        "                                    \"index\": \"vector-index\",\n",
        "                                    \"path\": \"embedding\",\n",
        "                                    \"queryVector\": query_embedding,\n",
        "                                    \"numCandidates\": 200,\n",
        "                                    \"limit\": 10,\n",
        "                                }\n",
        "                            }\n",
        "                        ],\n",
        "                        \"fts_pipeline\": [\n",
        "                            {\n",
        "                                \"$search\": {\n",
        "                                    \"index\": \"fts-index\",\n",
        "                                    \"text\": {\"query\": query, \"path\": \"caption\"},\n",
        "                                }\n",
        "                            },\n",
        "                            {\"$limit\": 10},\n",
        "                        ],\n",
        "                    }\n",
        "                },\n",
        "                \"combination\": {\n",
        "                    \"weights\": {\"vector_pipeline\": 0.5, \"fts_pipeline\": 0.5}\n",
        "                },\n",
        "                \"scoreDetails\": True,\n",
        "            }\n",
        "        },\n",
        "        {\n",
        "            \"$project\": {\n",
        "                \"_id\": 0,\n",
        "                \"video_title\": \"$metadata.video_title\",\n",
        "                \"start\": \"$metadata.start\",\n",
        "                \"end\": \"$metadata.end\",\n",
        "                \"score\": \"$scoreDetails.value\",\n",
        "            }\n",
        "        },\n",
        "        {\"$limit\": 3},\n",
        "    ]\n",
        "\n",
        "    results = collection.aggregate(pipeline)\n",
        "    for result in results:\n",
        "        print(\n",
        "            f\"{result.get('video_title')} ({format_time(result.get('start'))} - {format_time(result.get('end'))})\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "id": "17923831-57bf-4aed-9ee1-ed8196ddaa8c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classic French Croissants with Chef Marguerite Dubois (0:24 - 0:37)\n",
            "Classic French Croissants with Chef Marguerite Dubois (0:59 - 1:01)\n",
            "Classic French Croissants with Chef Marguerite Dubois (0:00 - 0:07)\n"
          ]
        }
      ],
      "source": [
        "vector_search(\"Rolling croissant dough\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "id": "3490f293-0b1d-4a66-82f3-30f9f443318f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Artisan Sourdough Bread Folding Technique (0:10 - 0:18)\n",
            "Artisan Sourdough Bread Folding Technique (0:19 - 0:20)\n",
            "Classic French Croissants with Chef Marguerite Dubois (0:24 - 0:37)\n"
          ]
        }
      ],
      "source": [
        "hybrid_search(\"Coil fold technique\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61a57c6f-7981-48b7-a0c8-0e5306241ecb",
      "metadata": {},
      "source": [
        "## Step 9: Building the Agentic Search Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "id": "6da79c72-de42-4f62-b8c1-697327f9f821",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define structured output schema\n",
        "output_schema = {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\"search\": {\"type\": \"string\", \"enum\": [\"vector\", \"hybrid\"]}},\n",
        "    \"required\": [\"search\"],\n",
        "    \"additionalProperties\": False,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "id": "704d4120-fbce-4b8c-b5f1-360d8216a3aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "SYSTEM_PROMPT = \"\"\"Given a query, choose the optimal search strategy to retrieve the most relevant video segments for it: \n",
        "\n",
        "vector\n",
        "- Best for: Visual actions and details, methods, concepts or general descriptions.\n",
        "- Examples: \"How to chop onions\", \"Grilling vegetables\"\n",
        "- Uses: Multimodal embeddings that capture both video and caption meaning\n",
        "\n",
        "hybrid\n",
        "- Best for: Specific names and terms such as techniques, chef names, dietary restrictions etc.\n",
        "- Examples: \"Coil fold technique\", \"Egg wash ingredients\"\n",
        "\n",
        "Default to vector unless exact word matching is critical.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "id": "93fc66bb-ae15-4c4b-a868-7bad3bc3426c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_search_type(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Use an LLM to determine the search strategy based on the query.\n",
        "\n",
        "    Args:\n",
        "        query (str): User query string\n",
        "\n",
        "    Returns:\n",
        "        str: Search type. One of \"vector\" or \"hybrid\"\n",
        "    \"\"\"\n",
        "    print(\"Determining search type...\")\n",
        "    response = anthropic_client.beta.messages.create(\n",
        "        model=\"claude-sonnet-4-5\",\n",
        "        max_tokens=50,\n",
        "        temperature=0,\n",
        "        betas=[\"structured-outputs-2025-11-13\"],\n",
        "        system=SYSTEM_PROMPT,\n",
        "        messages=[{\"role\": \"user\", \"content\": f\"Query: {query}\"}],\n",
        "        output_format={\"type\": \"json_schema\", \"schema\": output_schema},\n",
        "    )\n",
        "    search_type = json.loads(response.content[0].text).get(\"search\", \"unknown\")\n",
        "    print(f\"Using search type: {search_type}\")\n",
        "    return search_type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "id": "b92e7a4d-fb05-4838-bc42-2b00a21fe1da",
      "metadata": {},
      "outputs": [],
      "source": [
        "def search(query: str) -> None:\n",
        "    \"\"\"\n",
        "    Given a query, determine the search type and execute the search.\n",
        "\n",
        "    Args:\n",
        "        query (str): User quqery string\n",
        "    \"\"\"\n",
        "    search_type = get_search_type(query)\n",
        "    if search_type == \"vector\":\n",
        "        vector_search(query)\n",
        "    elif search_type == \"hybrid\":\n",
        "        hybrid_search(query)\n",
        "    else:\n",
        "        print(f\"Not a supported search type: {search_type}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "id": "19357309-57ec-42b1-896e-b45bb147661d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determining search type...\n",
            "Using search type: vector\n",
            "Classic French Croissants with Chef Marguerite Dubois (0:24 - 0:37)\n",
            "Classic French Croissants with Chef Marguerite Dubois (0:59 - 1:01)\n",
            "Classic French Croissants with Chef Marguerite Dubois (0:00 - 0:07)\n"
          ]
        }
      ],
      "source": [
        "search(\"Rolling croissant dough\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "id": "0da06647-0fb9-4d6a-a7af-a9ef9cea32a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determining search type...\n",
            "Using search type: hybrid\n",
            "Artisan Sourdough Bread Folding Technique (0:10 - 0:18)\n",
            "Artisan Sourdough Bread Folding Technique (0:19 - 0:20)\n",
            "Classic French Croissants with Chef Marguerite Dubois (0:24 - 0:37)\n"
          ]
        }
      ],
      "source": [
        "search(\"Coil fold technique\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_python3",
      "language": "python",
      "name": "conda_python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {}
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

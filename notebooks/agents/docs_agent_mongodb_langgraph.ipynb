{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-agents-lab/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM8rg08YhqZe"
   },
   "source": [
    "# Step 1: Setup prerequisites\n",
    "\n",
    "Replace `<MONGODB_URI>` with your **MongoDB connection string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXLWCWEghuOX"
   },
   "outputs": [],
   "source": [
    "# Retain the quotes (\"\") when pasting the URI\n",
    "MONGODB_URI = \"<MONGODB_URI>\"\n",
    "# Initialize a MongoDB Python client\n",
    "mongodb_client = MongoClient(MONGODB_URI, appname=\"devrel.workshop.agents\")\n",
    "# Check the connection to the server\n",
    "mongodb_client.admin.command(\"ping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do not change the values assigned to the variables below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Database name\n",
    "DB_NAME = \"mongodb_genai_devday\"\n",
    "# Name of the collection with full documents- used for summarization\n",
    "FULL_COLLECTION_NAME = \"mongodb-docs\"\n",
    "# Name of the collection for vector search- used for Q&A\n",
    "VS_COLLECTION_NAME = \"mongodb-docs-embedded\"\n",
    "# Name of the vector search index\n",
    "VS_INDEX_NAME = \"vector_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `DB_NAME` database.\n",
    "# Use the `mongodb_client` object instantiated above.\n",
    "db = <CODE_BLOCK_1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `VS_COLLECTION_NAME` collection.\n",
    "# Use the `db` and collection name defined above.\n",
    "vs_collection = <CODE_BLOCK_2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `FULL_COLLECTION_NAME` collection.\n",
    "# Use the `db` and collection name defined above.\n",
    "full_collection = <CODE_BLOCK_3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pick an LLM provider of your choice below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVERLESS_URL = os.environ.get(\"SERVERLESS_URL\")\n",
    "# Can be one of \"aws\", \"google\" or \"microsoft\"\n",
    "LLM_PROVIDER = \"aws\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUf3jtFzO4-V"
   },
   "source": [
    "# Step 2: Import data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    url=SERVERLESS_URL, json={\"task\": \"import_agents_data\", \"data\": MONGODB_URI}\n",
    ")\n",
    "if response.status_code == 200:\n",
    "    print(\n",
    "        f\"{vs_collection.count_documents({})} documents ingested into the {VS_COLLECTION_NAME} collection.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{full_collection.count_documents({})} documents ingested into the {FULL_COLLECTION_NAME} collection.\"\n",
    "    )\n",
    "else:\n",
    "    raise Exception(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create a vector search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index definition specifying:\n",
    "# path: Path to the embeddings field\n",
    "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
    "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
    "model = {\n",
    "    \"name\": VS_INDEX_NAME,\n",
    "    \"type\": \"vectorSearch\",\n",
    "    \"definition\": {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 384,\n",
    "                \"similarity\": \"cosine\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.create_search_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector search index with the above `model` for the `vs_collection` collection\n",
    "<CODE_BLOCK_4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZfheX5FiIhU"
   },
   "source": [
    "# Step 4: Create agent tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may see a warning upon running this cell. You can ignore it.\n",
    "from langchain.agents import tool\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the `gte-small` model using the Sentence Transformers library\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://huggingface.co/thenlper/gte-small#usage (See \"Use with sentence-transformers\" under Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a piece of text (`text`) as input, embeds it using the `embedding_model` instantiated above and returns the embedding as a list\n",
    "# An array can be converted to a list using the `tolist()` method\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Generate the embedding for a piece of text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to embed.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Embedding of the text as a list.\n",
    "    \"\"\"\n",
    "    embedding = <CODE_BLOCK_5>\n",
    "    return embedding.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Basic Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to retrieve relevant documents for a user query using vector search\n",
    "@tool\n",
    "def get_information_for_question_answering(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve information using vector search to answer a user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "    str: The retrieved information formatted as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embedding for the `user_query` using the `get_embedding` function defined above\n",
    "    query_embedding = <CODE_BLOCK_6>\n",
    "\n",
    "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
    "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
    "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
    "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
    "    pipeline = <CODE_BLOCK_7>\n",
    "\n",
    "    # Execute the aggregation `pipeline` against the `vs_collection` collection and store the results in `results`\n",
    "    results = <CODE_BLOCK_8>\n",
    "    # Concatenate the results into a string\n",
    "    context = \"\\n\\n\".join([doc.get(\"body\") for doc in results])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get page content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://www.mongodb.com/docs/manual/reference/method/db.collection.findOne/#return-all-but-the-excluded-fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to retrieve the content of a documentation page for summarization\n",
    "@tool\n",
    "def get_page_content_for_summarization(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve page content based on provided title.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string i.e. title of the documentation page.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the page.\n",
    "    \"\"\"\n",
    "    # Query the documents where the `title` field is equal to the `user_query`\n",
    "    query = <CODE_BLOCK_9>\n",
    "    # Only return the `body` field from the retrieved documents.\n",
    "    # NOTE: Set fields to include to 1, those to exclude to 0. `_id` is included by default, so exclude that.\n",
    "    projection = <CODE_BLOCK_10>\n",
    "    # Use the `query` and `projection` with the `find_one` method\n",
    "    # to get the `body` of the document with `title` equal to the `user_query` from the `full_collection` collection\n",
    "    document = <CODE_BLOCK_11>\n",
    "    if document:\n",
    "        return document[\"body\"]\n",
    "    else:\n",
    "        return \"Document not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of tools\n",
    "tools = [\n",
    "    get_information_for_question_answering,\n",
    "    get_page_content_for_summarization,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the `get_information_for_question_answering` tool with the query \"What are some best practices for data backups in MongoDB?\"\n",
    "# You should see a non-empty response\n",
    "get_information_for_question_answering.invoke(\n",
    "    \"What are some best practices for data backups in MongoDB?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the `get_page_content_for_summarization` tool with page title \"Create a MongoDB Deployment\"\n",
    "# You should see a non-empty response\n",
    "get_page_content_for_summarization.invoke(\"Create a MongoDB Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Define graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph state\n",
    "# We are only tracking chat messages but you can track other attributes as well\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Instantiate the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import load\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://python.langchain.com/docs/integrations/chat/fireworks/#instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the Langchain LLM object from our serverless endpoint\n",
    "llm_dict = requests.post(\n",
    "    url=SERVERLESS_URL, json={\"task\": \"get_llm\", \"data\": LLM_PROVIDER}\n",
    ").json()\n",
    "llm = load(llm_dict[\"llm\"], secrets_map=llm_dict[\"secrets_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chain-of-Thought (CoT) prompt template for the agent.\n",
    "# This includes a system prompt with a placeholder for tool names, and a placeholder for messages i.e. user queries and assistant responses\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are a helpful AI assistant.\"\n",
    "            \" You are provided with tools to answer questions and summarize technical documentation related to MongoDB.\"\n",
    "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
    "            \" Do not re-run tools unless absolutely necessary.\"\n",
    "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
    "            \" You have access to the following tools: {tool_names}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the prompt template with the tool names\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/#binding-tool-schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the `tools` to the `llm` instantiated above\n",
    "bind_tools = <CODE_BLOCK_12>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://python.langchain.com/v0.1/docs/expression_language/primitives/sequence/#the-pipe-operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the `prompt` with the tool-bound llm using the `|` operator\n",
    "llm_with_tools = <CODE_BLOCK_13>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the LLM is making the right tool calls\n",
    "llm_with_tools.invoke(\n",
    "    [\"Give me a summary of the page titled Create a MongoDB Deployment.\"]\n",
    ").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that the LLM is making the right tool calls\n",
    "llm_with_tools.invoke(\n",
    "    [\"What are some best practices for data backups in MongoDB?\"]\n",
    ").tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Define graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from typing import Dict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent node\n",
    "def agent(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Agent node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    # Get the messages from the graph `state`\n",
    "    messages = <CODE_BLOCK_14>\n",
    "    # Invoke `llm_with_tools` with `messages` using the `invoke` method\n",
    "    # HINT: See Step 6 for how to invoke `llm_with_tools`\n",
    "    result = <CODE_BLOCK_15>\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a map of tool name to tool call\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "pprint(tools_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool node\n",
    "def tool_node(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Tool node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Get the list of tool calls from messages\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # A tool_call looks as follows:\n",
    "    # {\n",
    "    #     \"name\": \"get_information_for_question_answering\",\n",
    "    #     \"args\": {\"user_query\": \"What are Atlas Triggers\"},\n",
    "    #     \"id\": \"call_H5TttXb423JfoulF1qVfPN3m\",\n",
    "    #     \"type\": \"tool_call\",\n",
    "    # }\n",
    "    # Iterate through `tool_calls`\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
    "        # HINT: See previous line to see how to extract attributes from `tool_call`\n",
    "        observation = <CODE_BLOCK_16>\n",
    "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
    "        # The `content` of the message is `observation` i.e. result of the tool call\n",
    "        # The `tool_call_id` can be obtained from the `tool_call`\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Define conditional edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditional routing function\n",
    "def route_tools(state: GraphState):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the tool node if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get messages from graph state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 0:\n",
    "        # Get the last AI message from messages\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # If yes, return \"tools\"\n",
    "        return \"tools\"\n",
    "    # If no, return END\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph\n",
    "graph = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://blog.langchain.dev/langgraph/#nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes to the `graph` using the `add_node` function\n",
    "# Add a `agent` node. The `agent` node should run the `agent` function\n",
    "<CODE_BLOCK_17>\n",
    "# Add a `tools` node. The `tools` node should run the `tool_node` function\n",
    "<CODE_BLOCK_18>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/low_level/#normal-edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add fixed edges to the `graph` using the `add_edge` method\n",
    "# Add an edge from the START node to the `agent` node\n",
    "<CODE_BLOCK_19>\n",
    "# Add an edge from the `tools` node to the `agent` node\n",
    "<CODE_BLOCK_20>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `add_conditional_edges` method to add a conditional edge from the `agent` node to the `tools` node\n",
    "# based on the output of the `route_tools` function\n",
    "<CODE_BLOCK_21>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the `graph`\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream outputs from the graph as they pass through its nodes\n",
    "def execute_graph(user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Add user input to the messages attribute of the graph state\n",
    "    # The role of the message should be \"user\" and content should be `user_input`\n",
    "    input = {\"messages\": [(\"user\", user_input)]}\n",
    "    # Pass input to the graph and stream the outputs\n",
    "    for output in app.stream(input):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Node {key}:\")\n",
    "            print(value)\n",
    "    print(\"---FINAL ANSWER---\")\n",
    "    print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"Give me a summary of the page titled Create a MongoDB Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Add memory to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.mongodb import MongoDBSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a MongoDB checkpointer\n",
    "checkpointer = MongoDBSaver(mongodb_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph with the checkpointer\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ“š https://langchain-ai.github.io/langgraph/concepts/persistence/#threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph(thread_id: str, user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        thread_id (str): Thread ID for the checkpointer\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Add user input to the messages attribute of the graph state\n",
    "    # The role of the message should be \"user\" and content should be `user_input`\n",
    "    input = {\"messages\": [(\"user\", user_input)]}\n",
    "    # Define a config containing the thread ID\n",
    "    config = <CODE_BLOCK_22>\n",
    "    # Pass `input` and `config` to the graph and stream outputs\n",
    "    for output in app.stream(input, config):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Node {key}:\")\n",
    "            print(value)\n",
    "    print(\"---FINAL ANSWER---\")\n",
    "    print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test graph execution with thread ID\n",
    "execute_graph(\n",
    "    \"1\",\n",
    "    \"What are some best practices for data backups in MongoDB?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question to ensure message history works\n",
    "execute_graph(\n",
    "    \"1\",\n",
    "    \"What did I just ask you?\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RM8rg08YhqZe",
    "UUf3jtFzO4-V",
    "Sm5QZdshwJLN"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09dcf4ce88064f11980bbefaad1ebc75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39563df9477648398456675ec51075aa",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_f4353368efbd4c3891f805ddc3d05e1b",
      "value": "Downloadingâ€‡data:â€‡100%"
     }
    },
    "164d16df28d24ab796b7c9cf85174800": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95e4af5b420242b7a6b74a18cad98961",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_dff65b579f0746ffae8739ecb0aa5a41",
      "value": "Generatingâ€‡trainâ€‡split:â€‡"
     }
    },
    "20d693a09c534414a5c4c0dd58cf94ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "278513c5a8b04a24b1823d38107f1e50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62e196b6d30746578e137c50b661f946",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ced7f9d61e06442a960dcda95852048e",
      "value": "â€‡102M/102Mâ€‡[00:06&lt;00:00,â€‡20.6MB/s]"
     }
    },
    "30fe0bcd02cb47f3ba23bb480e2eaaea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "373ed3b6307741859ab297c270cf42c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39563df9477648398456675ec51075aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41056c822b9d44559147d2b21416b956": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a43c349d171e469c8cc94d48060f775b",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_373ed3b6307741859ab297c270cf42c8",
      "value": "â€‡50000/0â€‡[00:04&lt;00:00,â€‡12390.43â€‡examples/s]"
     }
    },
    "62e196b6d30746578e137c50b661f946": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dbfebff68ff45628da832fac5233c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_164d16df28d24ab796b7c9cf85174800",
       "IPY_MODEL_e70e0d317f1e4e73bd95349ed1510cce",
       "IPY_MODEL_41056c822b9d44559147d2b21416b956"
      ],
      "layout": "IPY_MODEL_b1929fb112174c0abcd8004f6be0f880"
     }
    },
    "95e4af5b420242b7a6b74a18cad98961": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a43c349d171e469c8cc94d48060f775b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1929fb112174c0abcd8004f6be0f880": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cebfba144ba6418092df949783f93455": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09dcf4ce88064f11980bbefaad1ebc75",
       "IPY_MODEL_f2bd7bda4d0c4d93b88e53aeb4e1b62d",
       "IPY_MODEL_278513c5a8b04a24b1823d38107f1e50"
      ],
      "layout": "IPY_MODEL_d3941c633788427abb858b21e285088f"
     }
    },
    "ced7f9d61e06442a960dcda95852048e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d17d8c8f45ee44cd87dcd787c05dbdc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3941c633788427abb858b21e285088f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dff65b579f0746ffae8739ecb0aa5a41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e70e0d317f1e4e73bd95349ed1510cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f73ae771c24645c79fd41409a8fc7b34",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20d693a09c534414a5c4c0dd58cf94ed",
      "value": 1
     }
    },
    "f2bd7bda4d0c4d93b88e53aeb4e1b62d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30fe0bcd02cb47f3ba23bb480e2eaaea",
      "max": 102202622,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d17d8c8f45ee44cd87dcd787c05dbdc3",
      "value": 102202622
     }
    },
    "f4353368efbd4c3891f805ddc3d05e1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f73ae771c24645c79fd41409a8fc7b34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

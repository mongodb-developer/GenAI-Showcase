{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a technical documentation agent with MongoDB, Gemini, and LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mongodb-developer/GenAI-Showcase/blob/main/notebooks/agents/docs_agent_mngodb_langgraph.ipynb)\n",
    "\n",
    "#### **NOTE**: The  emoji indicates reference documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Install required libraries\n",
    "\n",
    "* **pymongo**: Python driver for MongoDB\n",
    "* **langchain**: Python library for LangChain, an LLM app orchestration framework\n",
    "* **langchain-google-genai**: Python library to use Google's GenAI models in LangChain\n",
    "* **langgraph**: Python library for LangChain's agent orchestration framework, LangGraph\n",
    "* **langgraph-checkpoint-mongodb**: Python library to add MongoDB as a checkpointer in LangGraph\n",
    "* **sentence_transformers**: Python library to use open-source ML models from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU pymongo langchain langchain-google-genai langgraph langgraph-checkpoint-mongodb sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM8rg08YhqZe"
   },
   "source": [
    "# Step 2: Setup prerequisites\n",
    "\n",
    "* Register for a [free MongoDB Atlas account](https://www.mongodb.com/cloud/atlas/register)\n",
    "* [Create a new database cluster](https://www.mongodb.com/docs/guides/atlas/cluster/)\n",
    "* [Obtain the connection string](https://www.mongodb.com/docs/guides/atlas/connection-string/) for your database cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oXLWCWEghuOX"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your MongoDB connection string: 路路路路路路路路\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1744923992, 1),\n",
       "  'signature': {'hash': b'\\x987\\x90 \\x86:iyr\\xc0\\x93\\x9c\\x03~\\x8b/\\xd0\\xe4\\xb5w',\n",
       "   'keyId': 7456513059255746561}},\n",
       " 'operationTime': Timestamp(1744923992, 1)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paste your MongoDB connection string. Be sure to replace the password placeholder with your actual password.\n",
    "MONGODB_URI = getpass.getpass(\"Enter your MongoDB connection string:\")\n",
    "# Initialize a MongoDB Python client\n",
    "mongodb_client = MongoClient(MONGODB_URI, appname=\"devrel.workshop.agents\")\n",
    "# Check the connection to the server\n",
    "mongodb_client.admin.command(\"ping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do not change the values assigned to the variables below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Database name\n",
    "DB_NAME = \"mongodb_genai_devday\"\n",
    "# Name of the collection with full documents- used for summarization\n",
    "FULL_COLLECTION_NAME = \"mongodb-docs\"\n",
    "# Name of the collection for vector search- used for Q&A\n",
    "VS_COLLECTION_NAME = \"mongodb-docs-embedded\"\n",
    "# Name of the vector search index\n",
    "VS_INDEX_NAME = \"vector_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `DB_NAME` database.\n",
    "db = mongodb_client[DB_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `VS_COLLECTION_NAME` collection.\n",
    "vs_collection = db[VS_COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `FULL_COLLECTION_NAME` collection.\n",
    "full_collection = db[FULL_COLLECTION_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint for data import and to get the LangChain LLM object\n",
    "SERVERLESS_URL = \"https://vtqjvgchmwcjwsrela2oyhlegu0hwqnw.lambda-url.us-west-2.on.aws/\"\n",
    "# Set the LLM provider to `google` to use Gemini 1.5 Pro as the brain of the agent\n",
    "LLM_PROVIDER = \"google\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUf3jtFzO4-V"
   },
   "source": [
    "# Step 3: Import data into MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 documents ingested into the mongodb-docs-embedded collection.\n",
      "20 documents ingested into the mongodb-docs collection.\n"
     ]
    }
   ],
   "source": [
    "# Make a request to the serverless function to import data into MongoDB\n",
    "response = requests.post(\n",
    "    url=SERVERLESS_URL, json={\"task\": \"import_agents_data\", \"data\": MONGODB_URI}\n",
    ")\n",
    "if response.status_code == 200:\n",
    "    print(\n",
    "        f\"{vs_collection.count_documents({})} documents ingested into the {VS_COLLECTION_NAME} collection.\"\n",
    "    )\n",
    "    print(\n",
    "        f\"{full_collection.count_documents({})} documents ingested into the {FULL_COLLECTION_NAME} collection.\"\n",
    "    )\n",
    "else:\n",
    "    raise Exception(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create a vector search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index definition specifying:\n",
    "# path: Path to the embeddings field\n",
    "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
    "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
    "model = {\n",
    "    \"name\": VS_INDEX_NAME,\n",
    "    \"type\": \"vectorSearch\",\n",
    "    \"definition\": {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 384,\n",
    "                \"similarity\": \"cosine\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.create_search_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vector_index'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector search index with the above `model` for the `vs_collection` collection\n",
    "vs_collection.create_search_index(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZfheX5FiIhU"
   },
   "source": [
    "# Step 5: Create agent tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may see a warning upon running this cell. You can ignore it.\n",
    "from typing import List\n",
    "\n",
    "from langchain.agents import tool\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ed8854733246978544c1f6ce08439d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c8447b41444c488ba9a0aa14d992b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff10baa2d7d444f828a60d6280ced4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f23109678f4f64ba1f70954b7dffd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade62eb2cf7843e8b3862f2f2330549f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/66.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836e9c24d374448680e88dd4e33fa57e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753996218ca347edafbd6fd25fca8fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d940d8e50b467281ff6086c7e51b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a3185930904fa887e1267e2279f4d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fd6e05e0a1497691f9123f4d3d1d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the `gte-small` model using the Sentence Transformers library\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://huggingface.co/thenlper/gte-small#usage (See \"Use with sentence-transformers\" under Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a piece of text (`text`) as input, embeds it using the `embedding_model` instantiated above and returns the embedding as a list\n",
    "# An array can be converted to a list using the `tolist()` method\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Generate the embedding for a piece of text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to embed.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Embedding of the text as a list.\n",
    "    \"\"\"\n",
    "    embedding = embedding_model.encode(text)\n",
    "    return embedding.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Basic Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to retrieve relevant documents for a user query using vector search\n",
    "@tool\n",
    "def get_information_for_question_answering(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve information using vector search to answer a user query.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "    str: The retrieved information formatted as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embedding for the `user_query` using the `get_embedding` function defined above\n",
    "    query_embedding = get_embedding(user_query)\n",
    "\n",
    "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
    "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
    "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$vectorSearch\": {\n",
    "                \"index\": VS_INDEX_NAME,\n",
    "                \"path\": \"embedding\",\n",
    "                \"queryVector\": query_embedding,\n",
    "                \"numCandidates\": 150,\n",
    "                \"limit\": 5,\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"_id\": 0,\n",
    "                \"body\": 1,\n",
    "                \"score\": {\"$meta\": \"vectorSearchScore\"},\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # Execute the aggregation `pipeline` against the `vs_collection` collection and store the results in `results`\n",
    "    results = vs_collection.aggregate(pipeline)\n",
    "    # Concatenate the results into a string\n",
    "    context = \"\\n\\n\".join([doc.get(\"body\") for doc in results])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get page content\n",
    "\n",
    " https://www.mongodb.com/docs/manual/reference/method/db.collection.findOne/#return-all-but-the-excluded-fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a tool to retrieve the content of a documentation page for summarization\n",
    "@tool\n",
    "def get_page_content_for_summarization(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve page content based on provided title.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string i.e. title of the documentation page.\n",
    "\n",
    "    Returns:\n",
    "    str: The content of the page.\n",
    "    \"\"\"\n",
    "    # Query the documents where the `title` field is equal to the `user_query`\n",
    "    query = {\"title\": user_query}\n",
    "    # Only return the `body` field from the retrieved documents.\n",
    "    # Set fields to include to 1, those to exclude to 0. `_id` is included by default, so exclude that.\n",
    "    projection = {\"_id\": 0, \"body\": 1}\n",
    "    # Use the `query` and `projection` with the `find_one` method\n",
    "    # to get the `body` of the document with `title` equal to the `user_query` from the `full_collection` collection\n",
    "    document = full_collection.find_one(query, projection)\n",
    "    if document:\n",
    "        return document[\"body\"]\n",
    "    else:\n",
    "        return \"Document not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the list of tools\n",
    "tools = [\n",
    "    get_information_for_question_answering,\n",
    "    get_page_content_for_summarization,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Backup and Restore Sharded Clusters\\n\\nThe following tutorials describe backup and restoration for sharded clusters:\\n\\nTo use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\\n\\nSharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\\n\\n- MongoDB Atlas\\n\\n- MongoDB Cloud Manager\\n\\n- MongoDB Ops Manager\\n\\nUse file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\\n\\nCreate backups using `mongodump` to back up each component in the cluster individually.\\n\\nCreate backups using `mongodump` to back up each component in the cluster individually.\\n\\nLimit the operation of the cluster balancer to provide a window for regular backup operations.\\n\\nAn outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\\n\\n# Configuration and Maintenance\\n\\nThis section describes routine management operations, including updating your MongoDB deployment's configuration.\\n\\nOutlines common MongoDB configurations and examples of best-practice configurations for common use cases.\\n\\nUpgrade a MongoDB deployment to a different patch release within the same major release series.\\n\\nStart, configure, and manage running `mongod` process.\\n\\nStop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\\n\\nArchive the current log files and start new ones.\\n\\n## Full Time Diagnostic Data Capture\\n\\nTo help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\\n\\nFTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\\n\\nMongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\\n\\nFTDC data **never** contains any of the following information:\\n\\n- Samples of queries, query predicates, or query results\\n\\n- Data sampled from any end-user collection or index\\n\\n- System or MongoDB user credentials or security certificates\\n\\n# Create a MongoDB Deployment\\n\\nYou can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\\n\\n## Create a Free MongoDB deployment on Atlas\\n\\nComplete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\\n\\n## Save your Credentials\\n\\nAfter you create your database user, save that user's username and password to a safe location for use in an upcoming step.\\n\\nAfter you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\\n\\nIf you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the `get_information_for_question_answering` tool with the query \"What are some best practices for data backups in MongoDB?\"\n",
    "# You should see a non-empty response\n",
    "get_information_for_question_answering.invoke(\n",
    "    \"What are some best practices for data backups in MongoDB?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Create a MongoDB Deployment\\n\\nYou can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\\n\\n## Create a Free MongoDB deployment on Atlas\\n\\nComplete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\\n\\n## Save your Credentials\\n\\nAfter you create your database user, save that user's username and password to a safe location for use in an upcoming step.\\n\\nAfter you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\\n\\nIf you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\\n\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the `get_page_content_for_summarization` tool with page title \"Create a MongoDB Deployment\"\n",
    "# You should see a non-empty response\n",
    "get_page_content_for_summarization.invoke(\"Create a MongoDB Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Define graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the graph state\n",
    "# We are only tracking chat messages but you can track other attributes as well\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Instantiate the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import load\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the Langchain LLM object from our serverless endpoint\n",
    "llm_dict = requests.post(\n",
    "    url=SERVERLESS_URL, json={\"task\": \"get_llm\", \"data\": LLM_PROVIDER}\n",
    ").json()\n",
    "llm = load(llm_dict[\"llm\"], secrets_map=llm_dict[\"secrets_map\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Chain-of-Thought (CoT) prompt template for the agent.\n",
    "# This includes a system prompt with a placeholder for tool names, and a placeholder for messages i.e. user queries and assistant responses\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"You are a helpful AI assistant.\"\n",
    "            \" You are provided with tools to answer questions and summarize technical documentation related to MongoDB.\"\n",
    "            \" Think step-by-step and use these tools to get the information required to answer the user query.\"\n",
    "            \" Do not re-run tools unless absolutely necessary.\"\n",
    "            \" If you are not able to get enough information using the tools, reply with I DON'T KNOW.\"\n",
    "            \" You have access to the following tools: {tool_names}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the prompt template with the tool names\n",
    "prompt = prompt.partial(tool_names=\", \".join([tool.name for tool in tools]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/#binding-tool-schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the `tools` to the `llm` instantiated above\n",
    "bind_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://python.langchain.com/v0.1/docs/expression_language/primitives/sequence/#the-pipe-operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain the `prompt` with the tool-bound llm using the `|` operator\n",
    "llm_with_tools = prompt | bind_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_page_content_for_summarization',\n",
       "  'args': {'user_query': 'Create a MongoDB Deployment'},\n",
       "  'id': '53420cec-7a27-4bb4-b726-98323cda465d',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the LLM is making the right tool calls\n",
    "llm_with_tools.invoke(\n",
    "    [\"Give me a summary of the page titled Create a MongoDB Deployment.\"]\n",
    ").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_information_for_question_answering',\n",
       "  'args': {'user_query': 'Best practices for MongoDB backups'},\n",
       "  'id': 'f4347ad8-a747-4f68-ae33-750f4458c481',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that the LLM is making the right tool calls\n",
    "llm_with_tools.invoke(\n",
    "    [\"What are some best practices for data backups in MongoDB?\"]\n",
    ").tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Define graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from typing import Dict\n",
    "\n",
    "from langchain_core.messages import ToolMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent node\n",
    "def agent(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Agent node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    # Get the messages from the graph `state`\n",
    "    messages = state[\"messages\"]\n",
    "    # Invoke `llm_with_tools` with `messages` using the `invoke` method\n",
    "    result = llm_with_tools.invoke(messages)\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'get_information_for_question_answering': StructuredTool(name='get_information_for_question_answering', description=\"Retrieve information using vector search to answer a user query.\\n\\nArgs:\\nuser_query (str): The user's query string.\\n\\nReturns:\\nstr: The retrieved information formatted as a string.\", args_schema=<class 'langchain_core.utils.pydantic.get_information_for_question_answering'>, func=<function get_information_for_question_answering at 0x7f9f2d15e950>),\n",
      " 'get_page_content_for_summarization': StructuredTool(name='get_page_content_for_summarization', description=\"Retrieve page content based on provided title.\\n\\nArgs:\\nuser_query (str): The user's query string i.e. title of the documentation page.\\n\\nReturns:\\nstr: The content of the page.\", args_schema=<class 'langchain_core.utils.pydantic.get_page_content_for_summarization'>, func=<function get_page_content_for_summarization at 0x7f9f2d1c70a0>)}\n"
     ]
    }
   ],
   "source": [
    "# Create a map of tool name to tool call\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "pprint(tools_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool node\n",
    "def tool_node(state: GraphState) -> Dict[str, List]:\n",
    "    \"\"\"\n",
    "    Tool node\n",
    "\n",
    "    Args:\n",
    "        state (GraphState): Graph state\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, List]: Updates to messages\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    # Get the list of tool calls from messages\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    # Iterate through `tool_calls`\n",
    "    for tool_call in tool_calls:\n",
    "        # Get the tool from `tools_by_name` using the `name` attribute of the `tool_call`\n",
    "        tool = tools_by_name[tool_call[\"name\"]]\n",
    "        # Invoke the `tool` using the `args` attribute of the `tool_call`\n",
    "        observation = tool.invoke(tool_call[\"args\"])\n",
    "        # Append the result of executing the tool to the `result` list as a ToolMessage\n",
    "        # The `content` of the message is `observation` i.e. result of the tool call\n",
    "        # The `tool_call_id` is obtained from the `tool_call`\n",
    "        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n",
    "    # Write `result` to the `messages` attribute of the graph state\n",
    "    return {\"messages\": result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Define conditional edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conditional routing function\n",
    "def route_tools(state: GraphState):\n",
    "    \"\"\"\n",
    "    Use in the conditional_edge to route to the tool node if the last message\n",
    "    has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    # Get messages from graph state\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if len(messages) > 0:\n",
    "        # Get the last AI message from messages\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "    # Check if the last message has tool calls\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # If yes, return \"tools\"\n",
    "        return \"tools\"\n",
    "    # If no, return END\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.graph import START, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph\n",
    "graph = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://blog.langchain.dev/langgraph/#nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f9e5ccd8c10>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add nodes to the `graph` using the `add_node` function\n",
    "# Add a `agent` node. The `agent` node should run the `agent` function\n",
    "graph.add_node(\"agent\", agent)\n",
    "# Add a `tools` node. The `tools` node should run the `tool_node` function\n",
    "graph.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://langchain-ai.github.io/langgraph/concepts/low_level/#normal-edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f9e5ccd8c10>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add fixed edges to the `graph` using the `add_edge` method\n",
    "# Add an edge from the START node to the `agent` node\n",
    "graph.add_edge(START, \"agent\")\n",
    "# Add an edge from the `tools` node to the `agent` node\n",
    "graph.add_edge(\"tools\", \"agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://langchain-ai.github.io/langgraph/concepts/low_level/#conditional-edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f9e5ccd8c10>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the `add_conditional_edges` method to add a conditional edge from the `agent` node to the `tools` node\n",
    "# based on the output of the `route_tools` function\n",
    "graph.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    route_tools,\n",
    "    {\"tools\": \"tools\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the `graph`\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the graph\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Execute the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream outputs from the graph as they pass through its nodes\n",
    "def execute_graph(user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Add user input to the messages attribute of the graph state\n",
    "    # The role of the message should be \"user\" and content should be `user_input`\n",
    "    input = {\"messages\": [(\"user\", user_input)]}\n",
    "    # Pass input to the graph and stream the outputs\n",
    "    for output in app.stream(input):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Node {key}:\")\n",
    "            print(value)\n",
    "    print(\"---FINAL ANSWER---\")\n",
    "    print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node agent:\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_information_for_question_answering', 'arguments': '{\"user_query\": \"Best practices for MongoDB backups\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-98409e63-e65b-4aeb-9c56-c66a77a701a8-0', tool_calls=[{'name': 'get_information_for_question_answering', 'args': {'user_query': 'Best practices for MongoDB backups'}, 'id': '0250b7f6-e270-4a3d-b1c8-74632f774e75', 'type': 'tool_call'}], usage_metadata={'input_tokens': 236, 'output_tokens': 18, 'total_tokens': 254, 'input_token_details': {'cache_read': 0}})]}\n",
      "Node tools:\n",
      "{'messages': [ToolMessage(content=\"# Backup and Restore Sharded Clusters\\n\\nThe following tutorials describe backup and restoration for sharded clusters:\\n\\nTo use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\\n\\nSharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\\n\\n- MongoDB Atlas\\n\\n- MongoDB Cloud Manager\\n\\n- MongoDB Ops Manager\\n\\nUse file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\\n\\nCreate backups using `mongodump` to back up each component in the cluster individually.\\n\\n# Configuration and Maintenance\\n\\nThis section describes routine management operations, including updating your MongoDB deployment's configuration.\\n\\nOutlines common MongoDB configurations and examples of best-practice configurations for common use cases.\\n\\nUpgrade a MongoDB deployment to a different patch release within the same major release series.\\n\\nStart, configure, and manage running `mongod` process.\\n\\nStop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\\n\\nArchive the current log files and start new ones.\\n\\nCreate backups using `mongodump` to back up each component in the cluster individually.\\n\\nLimit the operation of the cluster balancer to provide a window for regular backup operations.\\n\\nAn outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\\n\\n## Full Time Diagnostic Data Capture\\n\\nTo help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\\n\\nFTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\\n\\nMongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\\n\\nFTDC data **never** contains any of the following information:\\n\\n- Samples of queries, query predicates, or query results\\n\\n- Data sampled from any end-user collection or index\\n\\n- System or MongoDB user credentials or security certificates\\n\\n# MongoDB Performance\\n\\nAs you develop and operate applications with MongoDB, you may need to analyze the performance of the application and its database. When you encounter degraded performance, it is often a function of database access strategies, hardware availability, and the number of open database connections.\\n\\nSome users may experience performance limitations as a result of inadequate or inappropriate indexing strategies, or as a consequence of poor schema design patterns. Locking Performance discusses how these can impact MongoDB's internal locking.\\n\\nPerformance issues may indicate that the database is operating at capacity and that it is time to add additional capacity to the database. In particular, the application's working set should fit in the available physical memory.\\n\\nIn some cases performance issues may be temporary and related to abnormal traffic load. As discussed in Number of Connections, scaling can help relax excessive traffic.\\n\\nDatabase profiling can help you to understand what operations are causing degradation.\\n\\n## Locking Performance\", id='00bf90d1-bf1a-499f-9e12-2bebad1448b8', tool_call_id='0250b7f6-e270-4a3d-b1c8-74632f774e75')]}\n",
      "Node agent:\n",
      "{'messages': [AIMessage(content='Here are some best practices for MongoDB backups:\\n\\n*   Use file system snapshots to back up each component in a sharded cluster individually. This method is often more efficient than using MongoDB tools if your system allows file system backups.  It involves stopping the cluster balancer.\\n*   Back up each component individually using `mongodump`.\\n*   For sharded clusters, stop the balancer and use `fsync` or `db.fsyncLock()` on `mongos` to block writes during backups.  Consider coordinated backup and restore processes (MongoDB Atlas, Cloud Manager, or Ops Manager) to maintain transaction atomicity.\\n\\nThese practices ensure data consistency and efficient recovery.  For more detailed information, consult the MongoDB documentation on backup and restore procedures for sharded clusters.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-b904344f-6a29-4a8a-830f-1de6d9a2ba71-0', usage_metadata={'input_tokens': 980, 'output_tokens': 159, 'total_tokens': 1139, 'input_token_details': {'cache_read': 0}})]}\n",
      "---FINAL ANSWER---\n",
      "Here are some best practices for MongoDB backups:\n",
      "\n",
      "*   Use file system snapshots to back up each component in a sharded cluster individually. This method is often more efficient than using MongoDB tools if your system allows file system backups.  It involves stopping the cluster balancer.\n",
      "*   Back up each component individually using `mongodump`.\n",
      "*   For sharded clusters, stop the balancer and use `fsync` or `db.fsyncLock()` on `mongos` to block writes during backups.  Consider coordinated backup and restore processes (MongoDB Atlas, Cloud Manager, or Ops Manager) to maintain transaction atomicity.\n",
      "\n",
      "These practices ensure data consistency and efficient recovery.  For more detailed information, consult the MongoDB documentation on backup and restore procedures for sharded clusters.\n"
     ]
    }
   ],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node agent:\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_page_content_for_summarization', 'arguments': '{\"user_query\": \"Create a MongoDB Deployment\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-084645a6-b3e2-4ec1-a061-40bfbbeab4ce-0', tool_calls=[{'name': 'get_page_content_for_summarization', 'args': {'user_query': 'Create a MongoDB Deployment'}, 'id': 'd80c4727-6f0d-4ee3-ab47-b64db57e72fb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 237, 'output_tokens': 17, 'total_tokens': 254, 'input_token_details': {'cache_read': 0}})]}\n",
      "Node tools:\n",
      "{'messages': [ToolMessage(content=\"# Create a MongoDB Deployment\\n\\nYou can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\\n\\n## Create a Free MongoDB deployment on Atlas\\n\\nComplete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\\n\\n## Save your Credentials\\n\\nAfter you create your database user, save that user's username and password to a safe location for use in an upcoming step.\\n\\nAfter you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\\n\\nIf you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\\n\\n\", id='7b34f506-8e42-43a6-902f-a1a8337552df', tool_call_id='d80c4727-6f0d-4ee3-ab47-b64db57e72fb')]}\n",
      "Node agent:\n",
      "{'messages': [AIMessage(content=\"To create a free MongoDB deployment on Atlas, follow the Get Started with Atlas guide. This guide will walk you through setting up an Atlas account, creating a free tier deployment, and loading sample data.  After creating your database user, ensure to save the username and password securely.  Upon completion, you'll have a functional MongoDB deployment, user credentials, and sample data ready for use.  If you encounter any issues, consult the MongoDB Community Forums or submit feedback through the provided channels.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-97b14096-6e2b-46c9-8467-ad02a282ac1f-0', usage_metadata={'input_tokens': 439, 'output_tokens': 100, 'total_tokens': 539, 'input_token_details': {'cache_read': 0}})]}\n",
      "---FINAL ANSWER---\n",
      "To create a free MongoDB deployment on Atlas, follow the Get Started with Atlas guide. This guide will walk you through setting up an Atlas account, creating a free tier deployment, and loading sample data.  After creating your database user, ensure to save the username and password securely.  Upon completion, you'll have a functional MongoDB deployment, user credentials, and sample data ready for use.  If you encounter any issues, consult the MongoDB Community Forums or submit feedback through the provided channels.\n"
     ]
    }
   ],
   "source": [
    "# Test the graph execution to view end-to-end flow\n",
    "execute_graph(\"Give me a summary of the page titled Create a MongoDB Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12: Add memory to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.mongodb import MongoDBSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a MongoDB checkpointer\n",
    "checkpointer = MongoDBSaver(mongodb_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the graph with the checkpointer\n",
    "app = graph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " https://langchain-ai.github.io/langgraph/concepts/persistence/#threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_graph(thread_id: str, user_input: str) -> None:\n",
    "    \"\"\"\n",
    "    Stream outputs from the graph\n",
    "\n",
    "    Args:\n",
    "        thread_id (str): Thread ID for the checkpointer\n",
    "        user_input (str): User query string\n",
    "    \"\"\"\n",
    "    # Add user input to the messages attribute of the graph state\n",
    "    # The role of the message should be \"user\" and content should be `user_input`\n",
    "    input = {\"messages\": [(\"user\", user_input)]}\n",
    "    # Define a config containing the thread ID\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    # Pass `input` and `config` to the graph and stream outputs\n",
    "    for output in app.stream(input, config):\n",
    "        for key, value in output.items():\n",
    "            print(f\"Node {key}:\")\n",
    "            print(value)\n",
    "    print(\"---FINAL ANSWER---\")\n",
    "    print(value[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node agent:\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_information_for_question_answering', 'arguments': '{\"user_query\": \"best practices for MongoDB backups\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-c3af0447-bcca-4f25-ba60-eacfba1725b0-0', tool_calls=[{'name': 'get_information_for_question_answering', 'args': {'user_query': 'best practices for MongoDB backups'}, 'id': 'fb938f3b-db09-4eb6-9d68-31038703f08a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 236, 'output_tokens': 18, 'total_tokens': 254, 'input_token_details': {'cache_read': 0}})]}\n",
      "Node tools:\n",
      "{'messages': [ToolMessage(content=\"# Backup and Restore Sharded Clusters\\n\\nThe following tutorials describe backup and restoration for sharded clusters:\\n\\nTo use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\\n\\nSharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\\n\\n- MongoDB Atlas\\n\\n- MongoDB Cloud Manager\\n\\n- MongoDB Ops Manager\\n\\nUse file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\\n\\nCreate backups using `mongodump` to back up each component in the cluster individually.\\n\\n# Configuration and Maintenance\\n\\nThis section describes routine management operations, including updating your MongoDB deployment's configuration.\\n\\nOutlines common MongoDB configurations and examples of best-practice configurations for common use cases.\\n\\nUpgrade a MongoDB deployment to a different patch release within the same major release series.\\n\\nStart, configure, and manage running `mongod` process.\\n\\nStop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\\n\\nArchive the current log files and start new ones.\\n\\nCreate backups using `mongodump` to back up each component in the cluster individually.\\n\\nLimit the operation of the cluster balancer to provide a window for regular backup operations.\\n\\nAn outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.\\n\\n## Full Time Diagnostic Data Capture\\n\\nTo help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\\n\\nFTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\\n\\nMongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\\n\\nFTDC data **never** contains any of the following information:\\n\\n- Samples of queries, query predicates, or query results\\n\\n- Data sampled from any end-user collection or index\\n\\n- System or MongoDB user credentials or security certificates\\n\\n# MongoDB Performance\\n\\nAs you develop and operate applications with MongoDB, you may need to analyze the performance of the application and its database. When you encounter degraded performance, it is often a function of database access strategies, hardware availability, and the number of open database connections.\\n\\nSome users may experience performance limitations as a result of inadequate or inappropriate indexing strategies, or as a consequence of poor schema design patterns. Locking Performance discusses how these can impact MongoDB's internal locking.\\n\\nPerformance issues may indicate that the database is operating at capacity and that it is time to add additional capacity to the database. In particular, the application's working set should fit in the available physical memory.\\n\\nIn some cases performance issues may be temporary and related to abnormal traffic load. As discussed in Number of Connections, scaling can help relax excessive traffic.\\n\\nDatabase profiling can help you to understand what operations are causing degradation.\\n\\n## Locking Performance\", id='5035311d-78c8-4dd8-847d-b9e0d79e9584', tool_call_id='fb938f3b-db09-4eb6-9d68-31038703f08a')]}\n",
      "Node agent:\n",
      "{'messages': [AIMessage(content='Here are some best practices for MongoDB backups:\\n\\n*   Use file system snapshots to back up each component in a sharded cluster individually. This method is often more efficient than using MongoDB tools if your system allows file system backups.  It involves stopping the cluster balancer.\\n*   Back up each component individually using `mongodump`.\\n*   For sharded clusters, stop the balancer and use `fsync` or `db.fsyncLock()` on `mongos` to block writes during backups.  Consider using MongoDB Atlas, Cloud Manager, or Ops Manager for coordinated backups that maintain transaction atomicity.\\n\\nThese practices ensure data consistency and efficient recovery.  For more detailed information, consult the MongoDB documentation on backup and restore procedures for sharded clusters.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-bb3f42fb-6d05-493f-bccc-2443e1a011cd-0', usage_metadata={'input_tokens': 980, 'output_tokens': 156, 'total_tokens': 1136, 'input_token_details': {'cache_read': 0}})]}\n",
      "---FINAL ANSWER---\n",
      "Here are some best practices for MongoDB backups:\n",
      "\n",
      "*   Use file system snapshots to back up each component in a sharded cluster individually. This method is often more efficient than using MongoDB tools if your system allows file system backups.  It involves stopping the cluster balancer.\n",
      "*   Back up each component individually using `mongodump`.\n",
      "*   For sharded clusters, stop the balancer and use `fsync` or `db.fsyncLock()` on `mongos` to block writes during backups.  Consider using MongoDB Atlas, Cloud Manager, or Ops Manager for coordinated backups that maintain transaction atomicity.\n",
      "\n",
      "These practices ensure data consistency and efficient recovery.  For more detailed information, consult the MongoDB documentation on backup and restore procedures for sharded clusters.\n"
     ]
    }
   ],
   "source": [
    "# Test graph execution with thread ID\n",
    "execute_graph(\n",
    "    \"1\",\n",
    "    \"What are some best practices for data backups in MongoDB?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node agent:\n",
      "{'messages': [AIMessage(content='You asked about the best practices for data backups in MongoDB.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-pro-002', 'safety_ratings': []}, id='run-d76ad32a-2118-48e7-a1ee-203216334984-0', usage_metadata={'input_tokens': 1142, 'output_tokens': 13, 'total_tokens': 1155, 'input_token_details': {'cache_read': 0}})]}\n",
      "---FINAL ANSWER---\n",
      "You asked about the best practices for data backups in MongoDB.\n"
     ]
    }
   ],
   "source": [
    "# Follow-up question to ensure message history works\n",
    "execute_graph(\n",
    "    \"1\",\n",
    "    \"What did I just ask you?\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "RM8rg08YhqZe",
    "UUf3jtFzO4-V",
    "Sm5QZdshwJLN"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09dcf4ce88064f11980bbefaad1ebc75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39563df9477648398456675ec51075aa",
      "placeholder": "",
      "style": "IPY_MODEL_f4353368efbd4c3891f805ddc3d05e1b",
      "value": "Downloadingdata:100%"
     }
    },
    "164d16df28d24ab796b7c9cf85174800": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95e4af5b420242b7a6b74a18cad98961",
      "placeholder": "",
      "style": "IPY_MODEL_dff65b579f0746ffae8739ecb0aa5a41",
      "value": "Generatingtrainsplit:"
     }
    },
    "20d693a09c534414a5c4c0dd58cf94ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "278513c5a8b04a24b1823d38107f1e50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62e196b6d30746578e137c50b661f946",
      "placeholder": "",
      "style": "IPY_MODEL_ced7f9d61e06442a960dcda95852048e",
      "value": "102M/102M[00:06&lt;00:00,20.6MB/s]"
     }
    },
    "30fe0bcd02cb47f3ba23bb480e2eaaea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "373ed3b6307741859ab297c270cf42c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39563df9477648398456675ec51075aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41056c822b9d44559147d2b21416b956": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a43c349d171e469c8cc94d48060f775b",
      "placeholder": "",
      "style": "IPY_MODEL_373ed3b6307741859ab297c270cf42c8",
      "value": "50000/0[00:04&lt;00:00,12390.43examples/s]"
     }
    },
    "62e196b6d30746578e137c50b661f946": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7dbfebff68ff45628da832fac5233c93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_164d16df28d24ab796b7c9cf85174800",
       "IPY_MODEL_e70e0d317f1e4e73bd95349ed1510cce",
       "IPY_MODEL_41056c822b9d44559147d2b21416b956"
      ],
      "layout": "IPY_MODEL_b1929fb112174c0abcd8004f6be0f880"
     }
    },
    "95e4af5b420242b7a6b74a18cad98961": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a43c349d171e469c8cc94d48060f775b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1929fb112174c0abcd8004f6be0f880": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cebfba144ba6418092df949783f93455": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09dcf4ce88064f11980bbefaad1ebc75",
       "IPY_MODEL_f2bd7bda4d0c4d93b88e53aeb4e1b62d",
       "IPY_MODEL_278513c5a8b04a24b1823d38107f1e50"
      ],
      "layout": "IPY_MODEL_d3941c633788427abb858b21e285088f"
     }
    },
    "ced7f9d61e06442a960dcda95852048e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d17d8c8f45ee44cd87dcd787c05dbdc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d3941c633788427abb858b21e285088f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dff65b579f0746ffae8739ecb0aa5a41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e70e0d317f1e4e73bd95349ed1510cce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f73ae771c24645c79fd41409a8fc7b34",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20d693a09c534414a5c4c0dd58cf94ed",
      "value": 1
     }
    },
    "f2bd7bda4d0c4d93b88e53aeb4e1b62d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30fe0bcd02cb47f3ba23bb480e2eaaea",
      "max": 102202622,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d17d8c8f45ee44cd87dcd787c05dbdc3",
      "value": 102202622
     }
    },
    "f4353368efbd4c3891f805ddc3d05e1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f73ae771c24645c79fd41409a8fc7b34": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
